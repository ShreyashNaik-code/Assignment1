# Using an Embedding layer and classifier on the IMDB data

from keras.models import Sequential

from keras.layers import Flatten, Dense

model = Sequential()

#specifies maximum input length to the embedding layer so you can later flatten the embedded inputs
model.add(Embedding(10000, 8, input_length=maxlen)) 

# flattens the 3d tensor of embeddings into a 2d tensor of shape
model.add(Flatten())

#adds the clasifier on top
model.add(Dense(1, activation='sigmoid'))

model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])

model.summary()

history = model.fit(x_train, y_train,
epochs=10,
batch_size=32,
validation_split=0.2)
